# Proyecto 3 â€“ PredicciÃ³n de dureza final en aceros templados

Este proyecto aplica Machine Learning tradicional para predecir la **dureza final (HRC)** de aceros al carbono y baja aleaciÃ³n, a partir de su composiciÃ³n quÃ­mica y parÃ¡metros de tratamiento tÃ©rmico (templado y revenido).

## ğŸ“¦ Dataset

El dataset fue extraÃ­do de Kaggle:  
ğŸ“Œ *Tempering Data for Carbon and Low Alloy Steels*  
Incluye mÃ¡s de 1000 observaciones con las siguientes variables:

- ComposiciÃ³n quÃ­mica: C, Mn, P, S, Si, Ni, Cr, Mo, V, Al, Cu (% en peso)
- ParÃ¡metros del revenido: tiempo (s) y temperatura (Â°C)
- Tipo de acero (Steel Type), fuente y dureza final medida (HRC)

El dataset fue limpiado y procesado, eliminando la columna `Initial Hardness` por alta cantidad de valores faltantes.

## ğŸ§ª Objetivo del proyecto

Predecir la **dureza final HRC** post-templado y revenido usando modelos de regresiÃ³n supervisada.

## ğŸ“ Estructura del proyecto

```
.
â”œâ”€â”€ data/                   # Datos originales y limpios
â”œâ”€â”€ processed_data/        # Conjuntos de train/val/test
â”œâ”€â”€ models/                # Modelos entrenados (.pkl)
â”œâ”€â”€ mlruns/                # Experimentos registrados con MLflow
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb             # AnÃ¡lisis exploratorio de datos
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb   # Limpieza, escalado, codificaciÃ³n
â”‚   â”œâ”€â”€ 03_training_validation.ipynb # Entrenamiento y validaciÃ³n de modelos
â”‚   â””â”€â”€ 04_evaluation_export.ipynb   # EvaluaciÃ³n final y exportaciÃ³n
â””â”€â”€ requirements.txt       # LibrerÃ­as requeridas
```

## ğŸ§  Modelos evaluados

Se entrenaron y compararon los siguientes modelos:

- **RegresiÃ³n Lineal**
- **Ridge**
- **Lasso**
- **Random Forest**

El mejor desempeÃ±o fue obtenido con **Random Forest**, con los siguientes resultados sobre el conjunto de validaciÃ³n:

```
MSE: 3.95
MAE: 1.36
```

## ğŸ§ª EvaluaciÃ³n final

Evaluado en el conjunto de prueba:

```
MSE: 6.95
MAE: 1.73
```

## ğŸ§° Herramientas utilizadas

- Python 3.10
- pandas, numpy, scikit-learn, seaborn, matplotlib
- MLflow para registro de experimentos
- Jupyter Notebooks para desarrollo iterativo

## ğŸ“Œ Consideraciones

- Se descartaron columnas con mÃ¡s del 80% de valores faltantes
- Se utilizÃ³ codificaciÃ³n one-hot para variables categÃ³ricas
- Se aplicÃ³ `StandardScaler` a las variables numÃ©ricas
- Se utilizÃ³ `train_test_split` con particiÃ³n 60/20/20
- Se entrenÃ³ con validaciÃ³n manual y `RandomizedSearchCV`
